Before starting this chapter, let's go over the ideas behind its structure.\\
First, \cref{sec:FIinStatistics} will describe the Fisher Information as it is used in statistics. Some readers may wonder why we're discussing a statistical method describing probabilities when we've only talked about machine learning and neural networks before. The answer is, that the Fisher information matrix also
acts as the Riemannian metric describing the statistical manifold of the network regarding its loss. A brief introduction to this topic will be provided in \cref{sec:Manifolds}, where we explain the concept of manifolds, \cref{sec:RiemannianMetricAndFI}, where we go over the definition of metrics on those manifolds, \cref{sec:Curvature}, where we describe the concept of curvature and \cref{sec:ApplicationOfFIToNeuralNetworks}, where we cover how these concepts apply to neural networks. Since those sections are mathematically abstract, \cref{sec:FisherInterpretation} provides a brief recap with some added intuitive explanations. For more details, please refer to \cite{AmarisLectureNotes}, from which most of the following information is taken.