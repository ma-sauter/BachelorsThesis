In the previous sections we introduced the Fisher Information, first in a statistical context and later as the metric of a statistical manifold to be able to apply some of it's insights to neural network training.\\
Since the information provided in the last sections has been mathematically abstract and lacking intuition, let's quickly recap the basics of what we need to know and understand about the Fisher Information for the rest of this work.\\
First let's state the definition again. The FI is defined as 
\begin{equation}
	\begin{split}
		I_{i,j} &= \underset{x \in X}{E} \left[\tAbl{}{\theta_i}\log f(x|\theta)\cdot \tAbl{}{\theta_j}\log f(x|\theta)\right]\\
		&= \underset{(\mathbf{x}_i,\mathbf{y}_i)\in D}{E} \left[\tAbl{}{\theta_i}\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\cdot \tAbl{}{\theta_j}\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\right],
	\end{split}
\end{equation}
where the notation in the first line is used in the context of statistics and the one from the second line in the context of the manifold of neural network training.\\
We first introduced the FI as a statistical measure of how much information the measurement of a random variable contains about its underlying parameters.\\
For example let's say our experiment consists of throwing a biased coin, where the probability of heads is the underlying parameter of the random variable of the coin toss. We can now conduct an experiment with the goal of estimating the probability of the biased coin. Let's say we make 10 throws twice. The first time, we will use the full observation for the parameter estimation. We will exactly know the results of the coin toss \emph{for every single one} of the 10 throws. The second time, we will only know how often heads came up \emph{in total} in the 10 throws. We will lose the information about when exactly during these 10 trials we measured heads or tails. The Fisher Information yields the same value for both of these observables. This therefore means that the information about the parameter contained in the measurement is the same for both observations. To estimate the bias of the coin, it is perfectly sufficient to simply write down the total number of heads instead of the entire observation.\\
This how the Fisher Information was first introduced. Going further, we also introduced another way of obtaining the FI as the Riemannian metric of the statistical manifold corresponding to a neural network.\\
For this we considered a neural network along with a dataset and loss function as a statistical model. We did this by introducing a kind of probability $p_\theta(\mathbf{x}_i,\mathbf{y}_i) = \mathrm{e}^{-\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)}$. We can view this as the probability that our network with parameters $\theta$ produces the correct outputs $\mathbf{y}_i$ when given the inputs $\mathbf{x}_i$. In this view, we consider the family of probabilities $p_\theta$ that are functions taking network input-output pairs as input. That family of probabilities forms a statistical manifold. The manifold is a space with coordinates $\theta = \{\theta_1, \cdots, \theta_n\}$, where every point in the space corresponds to a probability function that depends on the $\theta$ coordinates of our space. The manifold we now constructed is curved, which means that it is only locally isometric to a euclidean space. Globally, euclidean geometry doesn't apply, which for example makes the shortest paths between points in the manifold curves in the coordinate system. When every point in the space is a probability function by itself, it's very hard to properly imagine lines between points and even the seemingly simple concept of distance becomes very abstract and confusing. Therefore, let's not dive too deeply into visualizations and first think about how we will measure distance and characterize curvature in this space. We first introduced the concept of a tangent space, which is different for every point in the manifold. The tangent space is, again hard to grasp, a abstract vector space where a vector is a differential operator corresponding to the derivative along a curve through the point. The reason we defined it is because through defining a inner product $\langle \cdot , \cdot \rangle$ on the tangent spaces we can obtain a metric on the manifold through $g_{ij} = \langle \mathbf{e}_i,\mathbf{e}_j\rangle$. As mentioned before the basis vectors on the tangent spaces are hard to imagine and we can't really find a definition of an inner product that easily, that's why we introduced a new space isomorph to the tangent space where defining the inner product feels natural. To obtain the inner product of two derivative operators we defined
\begin{equation}
	\langle \partial_i, \partial_j \rangle = \langle \partial_i \ell(x|\theta), \partial_j \ell(x|\theta) \rangle,
\end{equation}
where we naturally defined the inner product between the two distributions as
\begin{equation}
	 \langle \partial_i \ell_\theta(\mathbf{x}_i,\mathbf{y}_i), \partial_j \ell_\theta(\mathbf{x}_i,\mathbf{y}_i) \rangle = \underset{(\mathbf{x}_i,\mathbf{y}_i)\in D}{E} \big[\partial_i \ell_\theta(\mathbf{x}_i,\mathbf{y}_i) \cdot \partial_j \ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\big].
\end{equation}
Now we arrived at the definition of the metric of our manifold, which is equivalent to the Fisher Information matrix
\begin{equation}
	I_{ij} = g_{ij}.
\end{equation}
This equation is a bit easier to grasp, which means that we can finally try to get a bit of intuition about the connections between everything mentioned before. Distance between two points in a curved manifold along a curve $c$ is defined as 
\begin{equation}
	s = \int_{t_0}^{t_1} \sum_{i,j} \sqrt{g_{ij}\tAbl{\theta_i}{t}\tAbl{\theta_j}{t}} \mathrm{d}t. 
\end{equation}
If we only move along one coordinate $\theta_i$ on the curve, the distance reduces to 
\begin{equation}
	s = \int_{t_0}^{t_1} \sqrt{g_{ii}}\tAbl{\theta_i}{t} \mathrm{d}t. 
\end{equation}
Therefore the diagonal components of the FI tell us how far we move across the manifold when we change parameter $\theta_i$. Through inspection of the equation for the metric, it's clear that the distance between points created by changing a parameter relates to the expected change in the logarithm of the probability distribution, measured by the derivatives with respect to the parameter. We can directly map the parameter space onto the manifold of probabilities, but we need to reconsider the notion of distance for the manifold because distance in the euclidean parameter space doesn't generally translate to the measure of difference between the probabilities which we call distance. In the case of our neural network, the diagonal components are the expectation value of the squared derivative of the loss. This means that the diagonal values represent how much our subloss changes when we vary the corresponding parameter. The diagonal values represent how similar the change in the subloss function is under change in the two corresponding parameters. These information about the change of the loss regarding the parameters is now of high interest when considering neural network training. In general, calculating the FI is unfeasible though, because the parameters of networks can easily be in the millions. That's why the results of this work consider a few observations resulting from the fisher matrix and investigate some possibilities to obtain them from simpler observables of training.