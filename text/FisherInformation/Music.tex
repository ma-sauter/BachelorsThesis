In the previous sections we introduced the Fisher Information, first in a statistical context and later as the metric of a statistical manifold to be able to apply some of it's insights to neural networks training.\\
Since the information provided in the last sections has been mathematically abstract and lacking intuition, let's quickly recap the basics of what we need to know and understand about the Fisher Information for the continuity of this work.\\
First let's state the definition again. The FI is defined as 
\begin{equation}
	\begin{split}
		I_{i,j} &= \underset{x \in X}{E} \left[\tAbl{}{\theta_i}\log f(x|\theta)\cdot \tAbl{}{\theta_j}\log f(x|\theta)\right]\\
		&= \underset{(\mathbf{x}_i,\mathbf{y}_i)\in D}{E} \left[\tAbl{}{\theta_i}\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\cdot \tAbl{}{\theta_j}\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\right],
	\end{split}
\end{equation}
where the notation in the first line is used in the context of statistics and the one from the second line in the context of the manifold of neural network training.\\
We first introduced the FI as a statistical measure of how much information a measurement of a random variable contains about underlying parameters. For example let's say our experiment is throwing a biased coin, where the probability of heads is our parameter. We can now conduct an experiment with the goal of estimating the probability of the biased coin. Let's say we make 10 throws twice. The first time, our desired observable contains everything that happened. We will exactly know what the results of the coin toss for every single one of the 10 throws. The second time, we will only know how often heads came up in total in the 10 throws. We will lose the information on when exactly during these 10 experiments we measured heads or tails. Using the fisher information, we can calculate that both of these observables contain the same amount of information about the probability of the coin. This means that it is completely sufficient for estimating the bias of the coin to simply write down the total number of heads instead of the whole experiment.\\
This is widely applicable to many diverse problems and also how the Fisher Information was first introduced, but going further we also needed to introduce another way of obtaining the FI.\\
For this we considered a neural network along with a dataset and loss function as a statistical model. We did this by introducing a kind of probability $p_\theta(\mathbf{x}_i,\mathbf{y}_i) = \mathrm{e}^{-\ell_\theta(\mathbf{x}_i,\mathbf{y}_i)}$. We can say that this is the probability that our network with parameters $\theta$ produces the correct outputs $\mathbf{y}_i$ when given the inputs $\mathbf{x}_i$. In this view, we consider the family of probabilities $p_\theta$ that are functions taking network input-output pairs as input. That family of probabilities forms a statistical manifold. This means that we constructed a space with coordinates $\theta = \{\theta_1, \cdots, \theta_n\}$, where every point in the space corresponds to a probability function that depends on the $\theta$ coordinates of our space. The manifold we now constructed is curved, which means that it can locally be viewed as a euclidean space, but on a global scale the space is curved. This results in the shortest paths between points being curves in the coordinate system and many other unusual details. When every point in the space is a probability function by itself, it's very hard to properly imagine lines between points and even the seemingly simple concept of distance becomes very abstract and confusing. Therefore, let's not dive too deeply into visualizations and first think about how we will measure distance and characterize curvature in this space. We first introduced the concept of a tangent space, which is different for every point in the manifold. The tangent space is, again hard to grasp, a abstract vector space where a vector is a differential operator corresponding to the derivative along a curve through the point. The reason we defined it is because through defining a inner product $\langle \cdot , \cdot \rangle$ on the tangent spaces we can obtain a metric on the manifold through $g_{ij} = \langle \mathbf{e}_i,\mathbf{e}_j\rangle$. As mentioned before the basis vectors on the tangent spaces are hard to imagine and we can't really find a definition of an inner product that easily, that's why we introduced a new space isomorph to the tangent space where defining the inner product feels natural. To obtain the inner product of two derivative operators we defined
\begin{equation}
	\langle \partial_i, \partial_j \rangle = \langle \partial_i \ell(x|\theta), \partial_j \ell(x|\theta) \rangle,
\end{equation}
where we naturally defined the inner product between the two distributions as
\begin{equation}
	 \langle \partial_i \ell_\theta(\mathbf{x}_i,\mathbf{y}_i), \partial_j \ell_\theta(\mathbf{x}_i,\mathbf{y}_i) \rangle = \underset{(\mathbf{x}_i,\mathbf{y}_i)\in D}{E} \big[\partial_i \ell_\theta(\mathbf{x}_i,\mathbf{y}_i) \cdot \partial_j \ell_\theta(\mathbf{x}_i,\mathbf{y}_i)\big].
\end{equation}
Now we arrived at the definition of the metric of our manifold, which is equivalent to the Fisher Information matrix
\begin{equation}
	I_{ij} = g_{ij}.
\end{equation}
This equation is a bit easier to grasp, which means that we can finally try to get a bit of intuition about the connections between everything mentioned before. Distance between two points in a curved manifold along a curve $c$ is defined as 
\begin{equation}
	s = \int_{t_0}^{t_1} \sum_{i,j} \sqrt{g_{ij}\tAbl{\theta_i}{t}\tAbl{\theta_j}{t}} \mathrm{d}t. 
\end{equation}
If we only move along one coordinate $\theta_i$ on the curve, the distance reduces to 
\begin{equation}
	s = \int_{t_0}^{t_1} \sqrt{g_{ii}}\tAbl{\theta_i}{t} \mathrm{d}t. 
\end{equation}
Therefore the diagonal components of the FI tell us how far we move across the manifold when we change parameter $\theta_i$. Through inspection of the equation for the metric, it's clear that the distance between points created by changing a parameter relates to the expected change in the logarithm of the probability distribution, measured by the derivatives with respect to the parameter. We can directly map the parameter space onto the manifold of probabilities, but we need to reconsider the notion of distance for the manifold because distance in the euclidean parameter space doesn't generally translate to the measure of difference between the probabilities which we call distance. In the case of our neural network, the diagonal components are the expectation value of the squared derivative of the loss. This means that the diagonal values represent how much our subloss changes when we vary the corresponding parameter. The diagonal values represent how similar the change in the subloss function is under change in the two corresponding parameters. These information about the change of the loss regarding the parameters is now of high interest when considering neural network training. In general, calculating the FI is unfeasible though, because the parameters of networks can easily be in the millions. That's why the results of this work consider a few observations resulting from the fisher matrix and investigate some possibilities to obtain them from simpler observables of training.